{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d54ba45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04d2b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29d19cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa\n"
     ]
    }
   ],
   "source": [
    "with open ('artigos.txt', 'r', encoding = \"utf8\") as f:\n",
    "    artigos = f.read()\n",
    "print(artigos[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe4494c",
   "metadata": {},
   "source": [
    "### Precisamos refinar nossa base de dados para isso vamos separar ela por tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "180a376b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de palavras é 403031\n"
     ]
    }
   ],
   "source": [
    "# Método isapha() que verifica sé for todos os caracteres alfabéticos devolve True caso contrário False\n",
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras\n",
    "\n",
    "# o método .tokenize.word_tokenize() separa o texto todo em tokens\n",
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "print(f'O número de palavras é {len(lista_palavras)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b16f0",
   "metadata": {},
   "source": [
    "### Após a separação do texto em tokens é necessário fazer a normalização desses tokens, ou seja tranformar todas as letras maiúsculas em minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0bd19b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de palavras é 403031\n"
     ]
    }
   ],
   "source": [
    "def normalizacao(lista_palavras):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())    \n",
    "    return lista_normalizada\n",
    "\n",
    "lista_normalizada = normalizacao(lista_palavras)\n",
    "print(f'O número de palavras é {len(lista_normalizada)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18b8523",
   "metadata": {},
   "source": [
    "**Podemos observar que a quantidade de palavras ainda são as mesmas, mas agora precisamos retirar todas as palavras repetidas do nosso texto de teste com isso vamos utilizar a idéia de conjuntos com o método .set()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6c695a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de palavras é 403031\n"
     ]
    }
   ],
   "source": [
    "print(f'O número de palavras é {len(lista_palavras)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673c3f9e",
   "metadata": {},
   "source": [
    "## Algoritmo do corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ab77380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A função_lestras(). insere letras até encontrar a palavra correta.\n",
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "# A função deletando_caracteres(). remove letras que são digitas a mais que o necessário.\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "# A função troca_letra(). ele vai trocar letras por exemplo (lígica) em (lógica).\n",
    "def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "# A função inverte_letra(). ele vai inverter letras por exemplo (lgóica) em (lógica)\n",
    "def inverte_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "# A função gerador_turbinado(). Faz duas operaçoes que será capaz de tranformar (lóiigica) em em (lógica).\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    palavras_geradas += troca_letra(fatias)\n",
    "    palavras_geradas += inverte_letra(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "def probabilidade(palavra_gerada):\n",
    "    return frequencia[palavra_gerada]/total_palavras\n",
    "\n",
    "# A função max vai calcular o máximo de probabilidade da palavra estar correta\n",
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "# A função novo_corretor(). Vai adicionar a função gerador_turbinado()\n",
    "def novo_corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
    "    candidatos = [palavra]\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "    palavra_correta = max(candidatos, key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "# Função cria_dados_teste().cria uma lista de palavras para o teste.\n",
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, 'r', encoding = \"utf8\")\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste\n",
    "\n",
    "# Função avaliador(). Vai avaliar o quanto nosso corretor é acertivo.\n",
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1  \n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    taxa_desconhecidas = round(desconhecida*100/numero_palavras, 2)\n",
    "    print('Taxa de acerto {}% , desconhecidas {} % de {} palavras.'.format(taxa_acerto, taxa_desconhecidas, numero_palavras))\n",
    "\n",
    "    \n",
    "def avaliador_novo(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = novo_corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1  \n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    taxa_desconhecidas = round(desconhecida*100/numero_palavras, 2)\n",
    "    print('Taxa de acerto {}% , desconhecidas {} % de {} palavras.'.format(taxa_acerto, taxa_desconhecidas, numero_palavras))\n",
    "\n",
    "\n",
    "total_palavras = len(lista_normalizada)\n",
    "# Esse método .FreqDist() calcula a distribuição de frequencia das nossas palavras\n",
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "vocabulario = set(lista_normalizada)\n",
    "lista_teste = cria_dados_teste('palavras.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d01d4563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essa\n",
      "nessa\n"
     ]
    }
   ],
   "source": [
    "palavra = 'njessa'\n",
    "print(novo_corretor(palavra))\n",
    "print(corretor(palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8df0593e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto 76.34% , desconhecidas 6.99 % de 186 palavras.\n",
      "None\n",
      "Taxa de acerto 55.38% , desconhecidas 6.99 % de 186 palavras.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(avaliador(lista_teste, vocabulario))\n",
    "print(avaliador_novo(lista_teste, vocabulario))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19ac1b",
   "metadata": {},
   "source": [
    "**Podemos observar que utilizando a função novo_corretor() que utiliza o gerador_turbinado() temos uma taxa de acerto muito baixa porque ele devolve muitas palavras que tem mais de uma forma de ser correta como por exemplo (njessa) que o novo_corretor() nos trouxe \"essa\" e o corretor() nos trouxe \"nessa\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a545547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fisher\n",
      "aetsher\n"
     ]
    }
   ],
   "source": [
    "palavra = 'etsher'\n",
    "print(novo_corretor(palavra))\n",
    "print(corretor(palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21a62a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o\n",
      "tal\n"
     ]
    }
   ],
   "source": [
    "palavra = 'oal'\n",
    "print(novo_corretor(palavra))\n",
    "print(corretor(palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef47b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
